{"graph_0": {"_type": "graph", "format": "torch", "nodes": [{"name": "conv_stem", "id": 139768775209704, "class_name": "Conv2dSame(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)", "parameters": [["weight", [40, 3, 3, 3]]], "output_shape": [[256, 40, 32, 32]], "num_parameters": [1080]}, {"name": "bn1", "id": 139768775213008, "class_name": "BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)", "parameters": [["weight", [40]], ["bias", [40]]], "output_shape": [[256, 40, 32, 32]], "num_parameters": [40, 40]}, {"name": "blocks.0.0", "id": 139768822266960, "class_name": "DepthwiseSeparableConv(\n  (conv_dw): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n  (bn1): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pw): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_dw.weight", [40, 1, 3, 3]], ["bn1.weight", [40]], ["bn1.bias", [40]], ["se.conv_reduce.weight", [10, 40, 1, 1]], ["se.conv_reduce.bias", [10]], ["se.conv_expand.weight", [40, 10, 1, 1]], ["se.conv_expand.bias", [40]], ["conv_pw.weight", [24, 40, 1, 1]], ["bn2.weight", [24]], ["bn2.bias", [24]]], "output_shape": [[256, 24, 32, 32]], "num_parameters": [360, 40, 40, 400, 10, 400, 40, 960, 24, 24]}, {"name": "blocks.0.1", "id": 139768775212784, "class_name": "DepthwiseSeparableConv(\n  (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n  (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_dw.weight", [24, 1, 3, 3]], ["bn1.weight", [24]], ["bn1.bias", [24]], ["se.conv_reduce.weight", [6, 24, 1, 1]], ["se.conv_reduce.bias", [6]], ["se.conv_expand.weight", [24, 6, 1, 1]], ["se.conv_expand.bias", [24]], ["conv_pw.weight", [24, 24, 1, 1]], ["bn2.weight", [24]], ["bn2.bias", [24]]], "output_shape": [[256, 24, 32, 32]], "num_parameters": [216, 24, 24, 144, 6, 144, 24, 576, 24, 24]}, {"name": "blocks.1.0", "id": 139768775210992, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n  (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [144, 24, 1, 1]], ["bn1.weight", [144]], ["bn1.bias", [144]], ["conv_dw.weight", [144, 1, 3, 3]], ["bn2.weight", [144]], ["bn2.bias", [144]], ["se.conv_reduce.weight", [6, 144, 1, 1]], ["se.conv_reduce.bias", [6]], ["se.conv_expand.weight", [144, 6, 1, 1]], ["se.conv_expand.bias", [144]], ["conv_pwl.weight", [32, 144, 1, 1]], ["bn3.weight", [32]], ["bn3.bias", [32]]], "output_shape": [[256, 32, 16, 16]], "num_parameters": [3456, 144, 144, 1296, 144, 144, 864, 6, 864, 144, 4608, 32, 32]}, {"name": "blocks.1.1", "id": 139768775209368, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n  (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [192, 32, 1, 1]], ["bn1.weight", [192]], ["bn1.bias", [192]], ["conv_dw.weight", [192, 1, 3, 3]], ["bn2.weight", [192]], ["bn2.bias", [192]], ["se.conv_reduce.weight", [8, 192, 1, 1]], ["se.conv_reduce.bias", [8]], ["se.conv_expand.weight", [192, 8, 1, 1]], ["se.conv_expand.bias", [192]], ["conv_pwl.weight", [32, 192, 1, 1]], ["bn3.weight", [32]], ["bn3.bias", [32]]], "output_shape": [[256, 32, 16, 16]], "num_parameters": [6144, 192, 192, 1728, 192, 192, 1536, 8, 1536, 192, 6144, 32, 32]}, {"name": "blocks.1.2", "id": 139768774831632, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n  (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [192, 32, 1, 1]], ["bn1.weight", [192]], ["bn1.bias", [192]], ["conv_dw.weight", [192, 1, 3, 3]], ["bn2.weight", [192]], ["bn2.bias", [192]], ["se.conv_reduce.weight", [8, 192, 1, 1]], ["se.conv_reduce.bias", [8]], ["se.conv_expand.weight", [192, 8, 1, 1]], ["se.conv_expand.bias", [192]], ["conv_pwl.weight", [32, 192, 1, 1]], ["bn3.weight", [32]], ["bn3.bias", [32]]], "output_shape": [[256, 32, 16, 16]], "num_parameters": [6144, 192, 192, 1728, 192, 192, 1536, 8, 1536, 192, 6144, 32, 32]}, {"name": "blocks.2.0", "id": 139768822097008, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(192, 192, kernel_size=(5, 5), stride=(2, 2), groups=192, bias=False)\n  (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [192, 32, 1, 1]], ["bn1.weight", [192]], ["bn1.bias", [192]], ["conv_dw.weight", [192, 1, 5, 5]], ["bn2.weight", [192]], ["bn2.bias", [192]], ["se.conv_reduce.weight", [8, 192, 1, 1]], ["se.conv_reduce.bias", [8]], ["se.conv_expand.weight", [192, 8, 1, 1]], ["se.conv_expand.bias", [192]], ["conv_pwl.weight", [48, 192, 1, 1]], ["bn3.weight", [48]], ["bn3.bias", [48]]], "output_shape": [[256, 48, 8, 8]], "num_parameters": [6144, 192, 192, 4800, 192, 192, 1536, 8, 1536, 192, 9216, 48, 48]}, {"name": "blocks.2.1", "id": 139768775212896, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n  (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [288, 48, 1, 1]], ["bn1.weight", [288]], ["bn1.bias", [288]], ["conv_dw.weight", [288, 1, 5, 5]], ["bn2.weight", [288]], ["bn2.bias", [288]], ["se.conv_reduce.weight", [12, 288, 1, 1]], ["se.conv_reduce.bias", [12]], ["se.conv_expand.weight", [288, 12, 1, 1]], ["se.conv_expand.bias", [288]], ["conv_pwl.weight", [48, 288, 1, 1]], ["bn3.weight", [48]], ["bn3.bias", [48]]], "output_shape": [[256, 48, 8, 8]], "num_parameters": [13824, 288, 288, 7200, 288, 288, 3456, 12, 3456, 288, 13824, 48, 48]}, {"name": "blocks.2.2", "id": 139768789856440, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n  (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [288, 48, 1, 1]], ["bn1.weight", [288]], ["bn1.bias", [288]], ["conv_dw.weight", [288, 1, 5, 5]], ["bn2.weight", [288]], ["bn2.bias", [288]], ["se.conv_reduce.weight", [12, 288, 1, 1]], ["se.conv_reduce.bias", [12]], ["se.conv_expand.weight", [288, 12, 1, 1]], ["se.conv_expand.bias", [288]], ["conv_pwl.weight", [48, 288, 1, 1]], ["bn3.weight", [48]], ["bn3.bias", [48]]], "output_shape": [[256, 48, 8, 8]], "num_parameters": [13824, 288, 288, 7200, 288, 288, 3456, 12, 3456, 288, 13824, 48, 48]}, {"name": "blocks.3.0", "id": 139768789857168, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(288, 288, kernel_size=(3, 3), stride=(2, 2), groups=288, bias=False)\n  (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [288, 48, 1, 1]], ["bn1.weight", [288]], ["bn1.bias", [288]], ["conv_dw.weight", [288, 1, 3, 3]], ["bn2.weight", [288]], ["bn2.bias", [288]], ["se.conv_reduce.weight", [12, 288, 1, 1]], ["se.conv_reduce.bias", [12]], ["se.conv_expand.weight", [288, 12, 1, 1]], ["se.conv_expand.bias", [288]], ["conv_pwl.weight", [96, 288, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [13824, 288, 288, 2592, 288, 288, 3456, 12, 3456, 288, 27648, 96, 96]}, {"name": "blocks.3.1", "id": 139768789857728, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"name": "blocks.3.2", "id": 139768789858288, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"name": "blocks.3.3", "id": 139768789858848, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"name": "blocks.3.4", "id": 139768789859408, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"name": "blocks.4.0", "id": 139768789860248, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 5, 5]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [136, 576, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [55296, 576, 576, 14400, 576, 576, 13824, 24, 13824, 576, 78336, 136, 136]}, {"name": "blocks.4.1", "id": 139768790057480, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"name": "blocks.4.2", "id": 139768790058040, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"name": "blocks.4.3", "id": 139768774830848, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"name": "blocks.4.4", "id": 139768775323720, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"name": "blocks.5.0", "id": 139768775324336, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(816, 816, kernel_size=(5, 5), stride=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [232, 816, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 189312, 232, 232]}, {"name": "blocks.5.1", "id": 139768775294424, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"name": "blocks.5.2", "id": 139768775293248, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"name": "blocks.5.3", "id": 139768775291624, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"name": "blocks.5.4", "id": 139768775292464, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"name": "blocks.5.5", "id": 139768789352968, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"name": "blocks.6.0", "id": 139770858273592, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 3, 3]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [384, 1392, 1, 1]], ["bn3.weight", [384]], ["bn3.bias", [384]]], "output_shape": [[256, 384, 2, 2]], "num_parameters": [322944, 1392, 1392, 12528, 1392, 1392, 80736, 58, 80736, 1392, 534528, 384, 384]}, {"name": "blocks.6.1", "id": 139768822026480, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n  (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [2304, 384, 1, 1]], ["bn1.weight", [2304]], ["bn1.bias", [2304]], ["conv_dw.weight", [2304, 1, 3, 3]], ["bn2.weight", [2304]], ["bn2.bias", [2304]], ["se.conv_reduce.weight", [96, 2304, 1, 1]], ["se.conv_reduce.bias", [96]], ["se.conv_expand.weight", [2304, 96, 1, 1]], ["se.conv_expand.bias", [2304]], ["conv_pwl.weight", [384, 2304, 1, 1]], ["bn3.weight", [384]], ["bn3.bias", [384]]], "output_shape": [[256, 384, 2, 2]], "num_parameters": [884736, 2304, 2304, 20736, 2304, 2304, 221184, 96, 221184, 2304, 884736, 384, 384]}, {"name": "conv_head", "id": 139768775212280, "class_name": "Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)", "parameters": [["weight", [1536, 384, 1, 1]]], "output_shape": [[256, 1536, 2, 2]], "num_parameters": [589824]}, {"name": "bn2", "id": 139768775325064, "class_name": "BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)", "parameters": [["weight", [1536]], ["bias", [1536]]], "output_shape": [[256, 1536, 2, 2]], "num_parameters": [1536, 1536]}, {"name": "global_pool", "id": 139768775325512, "class_name": "SelectAdaptivePool2d (output_size=1, pool_type=avg)", "parameters": [], "output_shape": [[256, 1536, 1, 1]], "num_parameters": []}, {"name": "classifier", "id": 139768775211664, "class_name": "Linear(in_features=1536, out_features=4, bias=True)", "parameters": [["weight", [4, 1536]], ["bias", [4]]], "output_shape": [[256, 4]], "num_parameters": [6144, 4]}], "edges": []}, "_timestamp": 1579760594.3405685, "_runtime": 679.3048100471497, "gradients/classifier.weight": {"_type": "histogram", "values": [5.0, 0.0, 0.0, 5.0, 1.0, 2.0, 3.0, 3.0, 12.0, 8.0, 14.0, 20.0, 26.0, 23.0, 30.0, 58.0, 53.0, 72.0, 92.0, 94.0, 111.0, 145.0, 154.0, 163.0, 191.0, 223.0, 229.0, 243.0, 261.0, 294.0, 290.0, 291.0, 275.0, 295.0, 257.0, 280.0, 252.0, 193.0, 240.0, 197.0, 176.0, 137.0, 130.0, 102.0, 104.0, 95.0, 55.0, 47.0, 41.0, 24.0, 34.0, 26.0, 12.0, 16.0, 14.0, 7.0, 6.0, 2.0, 3.0, 5.0, 2.0, 0.0, 0.0, 1.0], "bins": [-0.0758378654718399, -0.07345797121524811, -0.07107807695865631, -0.06869818270206451, -0.06631828844547272, -0.06393839418888092, -0.061558496206998825, -0.05917860195040703, -0.05679870769381523, -0.054418813437223434, -0.05203891918063164, -0.04965902119874954, -0.047279126942157745, -0.04489923268556595, -0.04251933842897415, -0.040139444172382355, -0.03775954991579056, -0.03537965565919876, -0.032999761402606964, -0.030619867146015167, -0.02823997288942337, -0.025860074907541275, -0.023480180650949478, -0.02110028639435768, -0.018720392137765884, -0.016340497881174088, -0.01396060362458229, -0.011580705642700195, -0.009200811386108398, -0.0068209171295166016, -0.004441022872924805, -0.002061128616333008, 0.00031876564025878906, 0.002698659896850586, 0.005078554153442383, 0.00745844841003418, 0.009838342666625977, 0.012218236923217773, 0.01459813117980957, 0.016978025436401367, 0.019357919692993164, 0.021737821400165558, 0.024117715656757355, 0.02649760991334915, 0.02887750416994095, 0.031257398426532745, 0.03363729268312454, 0.03601718693971634, 0.038397081196308136, 0.04077697545289993, 0.04315686970949173, 0.04553676396608353, 0.047916658222675323, 0.05029655992984772, 0.052676454186439514, 0.05505634844303131, 0.05743624269962311, 0.059816136956214905, 0.0621960312128067, 0.0645759254693985, 0.0669558197259903, 0.06933571398258209, 0.07171560823917389, 0.07409550249576569, 0.07647539675235748]}, "gradients/classifier.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.016525669023394585, -0.015998825430870056, -0.015471981838345528, -0.014945138245821, -0.01441829465329647, -0.013891451060771942, -0.013364607468247414, -0.012837763875722885, -0.012310920283198357, -0.011784076690673828, -0.0112572330981493, -0.010730389505624771, -0.010203544981777668, -0.00967670138925314, -0.009149857796728611, -0.008623014204204082, -0.008096170611679554, -0.0075693270191550255, -0.007042483426630497, -0.0065156398341059685, -0.00598879624158144, -0.0054619526490569115, -0.004935109056532383, -0.0044082654640078545, -0.0038814209401607513, -0.003354577347636223, -0.0028277337551116943, -0.002300890162587166, -0.0017740465700626373, -0.0012472029775381088, -0.0007203593850135803, -0.00019351579248905182, 0.0003333278000354767, 0.0008601713925600052, 0.0013870149850845337, 0.0019138585776090622, 0.0024407021701335907, 0.002967545762658119, 0.0034943893551826477, 0.004021232947707176, 0.004548076540231705, 0.005074920132756233, 0.005601763725280762, 0.00612860731780529, 0.006655450910329819, 0.007182294502854347, 0.007709138095378876, 0.008235981687903404, 0.008762827143073082, 0.00928967073559761, 0.009816514328122139, 0.010343357920646667, 0.010870201513171196, 0.011397045105695724, 0.011923888698220253, 0.012450732290744781, 0.01297757588326931, 0.013504419475793839, 0.014031263068318367, 0.014558106660842896, 0.015084950253367424, 0.015611791983246803, 0.01613863743841648, 0.01666547916829586, 0.017192324623465538]}, "_step": 0}
