{"graph_0": {"_type": "graph", "format": "torch", "nodes": [{"name": "conv_stem", "id": 140247600853960, "class_name": "Conv2dSame(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)", "parameters": [["weight", [40, 3, 3, 3]]], "output_shape": [[256, 40, 32, 32]], "num_parameters": [1080]}, {"name": "bn1", "id": 140247600854128, "class_name": "BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)", "parameters": [["weight", [40]], ["bias", [40]]], "output_shape": [[256, 40, 32, 32]], "num_parameters": [40, 40]}, {"name": "blocks.0.0", "id": 140247647562888, "class_name": "DepthwiseSeparableConv(\n  (conv_dw): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n  (bn1): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pw): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_dw.weight", [40, 1, 3, 3]], ["bn1.weight", [40]], ["bn1.bias", [40]], ["se.conv_reduce.weight", [10, 40, 1, 1]], ["se.conv_reduce.bias", [10]], ["se.conv_expand.weight", [40, 10, 1, 1]], ["se.conv_expand.bias", [40]], ["conv_pw.weight", [24, 40, 1, 1]], ["bn2.weight", [24]], ["bn2.bias", [24]]], "output_shape": [[256, 24, 32, 32]], "num_parameters": [360, 40, 40, 400, 10, 400, 40, 960, 24, 24]}, {"name": "blocks.0.1", "id": 140247647559864, "class_name": "DepthwiseSeparableConv(\n  (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n  (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_dw.weight", [24, 1, 3, 3]], ["bn1.weight", [24]], ["bn1.bias", [24]], ["se.conv_reduce.weight", [6, 24, 1, 1]], ["se.conv_reduce.bias", [6]], ["se.conv_expand.weight", [24, 6, 1, 1]], ["se.conv_expand.bias", [24]], ["conv_pw.weight", [24, 24, 1, 1]], ["bn2.weight", [24]], ["bn2.bias", [24]]], "output_shape": [[256, 24, 32, 32]], "num_parameters": [216, 24, 24, 144, 6, 144, 24, 576, 24, 24]}, {"name": "blocks.1.0", "id": 140247647562944, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n  (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [144, 24, 1, 1]], ["bn1.weight", [144]], ["bn1.bias", [144]], ["conv_dw.weight", [144, 1, 3, 3]], ["bn2.weight", [144]], ["bn2.bias", [144]], ["se.conv_reduce.weight", [6, 144, 1, 1]], ["se.conv_reduce.bias", [6]], ["se.conv_expand.weight", [144, 6, 1, 1]], ["se.conv_expand.bias", [144]], ["conv_pwl.weight", [32, 144, 1, 1]], ["bn3.weight", [32]], ["bn3.bias", [32]]], "output_shape": [[256, 32, 16, 16]], "num_parameters": [3456, 144, 144, 1296, 144, 144, 864, 6, 864, 144, 4608, 32, 32]}, {"name": "blocks.1.1", "id": 140247647561768, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n  (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [192, 32, 1, 1]], ["bn1.weight", [192]], ["bn1.bias", [192]], ["conv_dw.weight", [192, 1, 3, 3]], ["bn2.weight", [192]], ["bn2.bias", [192]], ["se.conv_reduce.weight", [8, 192, 1, 1]], ["se.conv_reduce.bias", [8]], ["se.conv_expand.weight", [192, 8, 1, 1]], ["se.conv_expand.bias", [192]], ["conv_pwl.weight", [32, 192, 1, 1]], ["bn3.weight", [32]], ["bn3.bias", [32]]], "output_shape": [[256, 32, 16, 16]], "num_parameters": [6144, 192, 192, 1728, 192, 192, 1536, 8, 1536, 192, 6144, 32, 32]}, {"name": "blocks.1.2", "id": 140247647534720, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n  (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [192, 32, 1, 1]], ["bn1.weight", [192]], ["bn1.bias", [192]], ["conv_dw.weight", [192, 1, 3, 3]], ["bn2.weight", [192]], ["bn2.bias", [192]], ["se.conv_reduce.weight", [8, 192, 1, 1]], ["se.conv_reduce.bias", [8]], ["se.conv_expand.weight", [192, 8, 1, 1]], ["se.conv_expand.bias", [192]], ["conv_pwl.weight", [32, 192, 1, 1]], ["bn3.weight", [32]], ["bn3.bias", [32]]], "output_shape": [[256, 32, 16, 16]], "num_parameters": [6144, 192, 192, 1728, 192, 192, 1536, 8, 1536, 192, 6144, 32, 32]}, {"name": "blocks.2.0", "id": 140247647563504, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(192, 192, kernel_size=(5, 5), stride=(2, 2), groups=192, bias=False)\n  (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [192, 32, 1, 1]], ["bn1.weight", [192]], ["bn1.bias", [192]], ["conv_dw.weight", [192, 1, 5, 5]], ["bn2.weight", [192]], ["bn2.bias", [192]], ["se.conv_reduce.weight", [8, 192, 1, 1]], ["se.conv_reduce.bias", [8]], ["se.conv_expand.weight", [192, 8, 1, 1]], ["se.conv_expand.bias", [192]], ["conv_pwl.weight", [48, 192, 1, 1]], ["bn3.weight", [48]], ["bn3.bias", [48]]], "output_shape": [[256, 48, 8, 8]], "num_parameters": [6144, 192, 192, 4800, 192, 192, 1536, 8, 1536, 192, 9216, 48, 48]}, {"name": "blocks.2.1", "id": 140247600591984, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n  (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [288, 48, 1, 1]], ["bn1.weight", [288]], ["bn1.bias", [288]], ["conv_dw.weight", [288, 1, 5, 5]], ["bn2.weight", [288]], ["bn2.bias", [288]], ["se.conv_reduce.weight", [12, 288, 1, 1]], ["se.conv_reduce.bias", [12]], ["se.conv_expand.weight", [288, 12, 1, 1]], ["se.conv_expand.bias", [288]], ["conv_pwl.weight", [48, 288, 1, 1]], ["bn3.weight", [48]], ["bn3.bias", [48]]], "output_shape": [[256, 48, 8, 8]], "num_parameters": [13824, 288, 288, 7200, 288, 288, 3456, 12, 3456, 288, 13824, 48, 48]}, {"name": "blocks.2.2", "id": 140247600591256, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n  (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [288, 48, 1, 1]], ["bn1.weight", [288]], ["bn1.bias", [288]], ["conv_dw.weight", [288, 1, 5, 5]], ["bn2.weight", [288]], ["bn2.bias", [288]], ["se.conv_reduce.weight", [12, 288, 1, 1]], ["se.conv_reduce.bias", [12]], ["se.conv_expand.weight", [288, 12, 1, 1]], ["se.conv_expand.bias", [288]], ["conv_pwl.weight", [48, 288, 1, 1]], ["bn3.weight", [48]], ["bn3.bias", [48]]], "output_shape": [[256, 48, 8, 8]], "num_parameters": [13824, 288, 288, 7200, 288, 288, 3456, 12, 3456, 288, 13824, 48, 48]}, {"name": "blocks.3.0", "id": 140247600592320, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(288, 288, kernel_size=(3, 3), stride=(2, 2), groups=288, bias=False)\n  (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [288, 48, 1, 1]], ["bn1.weight", [288]], ["bn1.bias", [288]], ["conv_dw.weight", [288, 1, 3, 3]], ["bn2.weight", [288]], ["bn2.bias", [288]], ["se.conv_reduce.weight", [12, 288, 1, 1]], ["se.conv_reduce.bias", [12]], ["se.conv_expand.weight", [288, 12, 1, 1]], ["se.conv_expand.bias", [288]], ["conv_pwl.weight", [96, 288, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [13824, 288, 288, 2592, 288, 288, 3456, 12, 3456, 288, 27648, 96, 96]}, {"name": "blocks.3.1", "id": 140247600592992, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"name": "blocks.3.2", "id": 140247600593384, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"name": "blocks.3.3", "id": 140247600593944, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"name": "blocks.3.4", "id": 140247600594504, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"name": "blocks.4.0", "id": 140247623995856, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 5, 5]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [136, 576, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [55296, 576, 576, 14400, 576, 576, 13824, 24, 13824, 576, 78336, 136, 136]}, {"name": "blocks.4.1", "id": 140247623996416, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"name": "blocks.4.2", "id": 140247623996976, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"name": "blocks.4.3", "id": 140247623997536, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"name": "blocks.4.4", "id": 140247623998096, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"name": "blocks.5.0", "id": 140247623998936, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(816, 816, kernel_size=(5, 5), stride=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [232, 816, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 189312, 232, 232]}, {"name": "blocks.5.1", "id": 140247600786344, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"name": "blocks.5.2", "id": 140247600787296, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"name": "blocks.5.3", "id": 140247600855248, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"name": "blocks.5.4", "id": 140247600856480, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"name": "blocks.5.5", "id": 140247600855864, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"name": "blocks.6.0", "id": 140247623341336, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 3, 3]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [384, 1392, 1, 1]], ["bn3.weight", [384]], ["bn3.bias", [384]]], "output_shape": [[256, 384, 2, 2]], "num_parameters": [322944, 1392, 1392, 12528, 1392, 1392, 80736, 58, 80736, 1392, 534528, 384, 384]}, {"name": "blocks.6.1", "id": 140247623342512, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n  (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [2304, 384, 1, 1]], ["bn1.weight", [2304]], ["bn1.bias", [2304]], ["conv_dw.weight", [2304, 1, 3, 3]], ["bn2.weight", [2304]], ["bn2.bias", [2304]], ["se.conv_reduce.weight", [96, 2304, 1, 1]], ["se.conv_reduce.bias", [96]], ["se.conv_expand.weight", [2304, 96, 1, 1]], ["se.conv_expand.bias", [2304]], ["conv_pwl.weight", [384, 2304, 1, 1]], ["bn3.weight", [384]], ["bn3.bias", [384]]], "output_shape": [[256, 384, 2, 2]], "num_parameters": [884736, 2304, 2304, 20736, 2304, 2304, 221184, 96, 221184, 2304, 884736, 384, 384]}, {"name": "conv_head", "id": 140247600856984, "class_name": "Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)", "parameters": [["weight", [1536, 384, 1, 1]]], "output_shape": [[256, 1536, 2, 2]], "num_parameters": [589824]}, {"name": "bn2", "id": 140247623343856, "class_name": "BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)", "parameters": [["weight", [1536]], ["bias", [1536]]], "output_shape": [[256, 1536, 2, 2]], "num_parameters": [1536, 1536]}, {"name": "global_pool", "id": 140247623344080, "class_name": "SelectAdaptivePool2d (output_size=1, pool_type=avg)", "parameters": [], "output_shape": [[256, 1536, 1, 1]], "num_parameters": []}, {"name": "classifier", "id": 140247623438464, "class_name": "Linear(in_features=1536, out_features=4, bias=True)", "parameters": [["weight", [4, 1536]], ["bias", [4]]], "output_shape": [[256, 4]], "num_parameters": [6144, 4]}], "edges": []}, "gradients/classifier.weight": {"_type": "histogram", "values": [2.0, 1.0, 2.0, 4.0, 0.0, 4.0, 2.0, 1.0, 12.0, 6.0, 15.0, 17.0, 22.0, 23.0, 30.0, 46.0, 55.0, 66.0, 84.0, 106.0, 98.0, 129.0, 160.0, 164.0, 183.0, 204.0, 240.0, 235.0, 280.0, 265.0, 309.0, 298.0, 276.0, 295.0, 274.0, 271.0, 264.0, 215.0, 213.0, 210.0, 185.0, 146.0, 133.0, 106.0, 102.0, 93.0, 51.0, 52.0, 44.0, 28.0, 29.0, 27.0, 13.0, 16.0, 12.0, 9.0, 2.0, 3.0, 3.0, 6.0, 2.0, 0.0, 0.0, 1.0], "bins": [-0.07611153274774551, -0.07373648881912231, -0.07136144489049911, -0.06898639351129532, -0.06661134958267212, -0.06423630565404892, -0.06186126172542572, -0.05948621779680252, -0.05711117014288902, -0.054736122488975525, -0.052361078560352325, -0.049986034631729126, -0.047610990703105927, -0.04523594304919243, -0.04286089912056923, -0.04048585146665573, -0.03811080753803253, -0.03573576360940933, -0.033360715955495834, -0.030985672026872635, -0.028610624372959137, -0.026235580444335938, -0.023860536515712738, -0.02148548886179924, -0.01911044493317604, -0.01673540100455284, -0.014360353350639343, -0.011985309422016144, -0.009610265493392944, -0.007235221564769745, -0.0048601701855659485, -0.002485126256942749, -0.00011008232831954956, 0.00226496160030365, 0.004640005528926849, 0.007015056908130646, 0.009390100836753845, 0.011765144765377045, 0.014140188694000244, 0.016515232622623444, 0.01889028400182724, 0.02126532793045044, 0.02364037185907364, 0.02601541578769684, 0.028390459716320038, 0.030765503644943237, 0.033140555024147034, 0.03551559895277023, 0.03789064288139343, 0.04026568681001663, 0.04264073073863983, 0.04501578211784363, 0.04739082604646683, 0.04976586252450943, 0.052140913903713226, 0.05451596528291702, 0.056891001760959625, 0.05926605314016342, 0.061641089618206024, 0.06401614099740982, 0.06639119237661362, 0.06876622885465622, 0.07114128023386002, 0.07351631671190262, 0.07589136809110641]}, "_runtime": 508.20136880874634, "gradients/classifier.bias": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.005852697417140007, -0.0055413637310266495, -0.005230029579252005, -0.004918695893138647, -0.004607361741364002, -0.004296028055250645, -0.003984694369137287, -0.003673360450193286, -0.0033620265312492847, -0.0030506926123052835, -0.0027393586933612823, -0.002428025007247925, -0.0021166910883039236, -0.0018053571693599224, -0.0014940234832465649, -0.00118268933147192, -0.0008713556453585625, -0.0005600219592452049, -0.0002486878074705601, 6.264587864279747e-05, 0.0003739800304174423, 0.0006853137165307999, 0.0009966474026441574, 0.0013079815544188023, 0.0016193152405321598, 0.0019306489266455173, 0.002241983078420162, 0.0025533167645335197, 0.0028646504506468773, 0.003175984136760235, 0.003487318754196167, 0.0037986524403095245, 0.004109986126422882, 0.00442131981253624, 0.004732653498649597, 0.005043988116085529, 0.005355321802198887, 0.005666655488312244, 0.005977989174425602, 0.0062893228605389595, 0.006600657477974892, 0.006911991164088249, 0.007223324850201607, 0.007534658536314964, 0.007845992222428322, 0.00815732590854168, 0.008468660525977612, 0.008779994212090969, 0.009091327898204327, 0.009402661584317684, 0.009713995270431042, 0.010025329887866974, 0.010336663573980331, 0.010647997260093689, 0.010959330946207047, 0.011270664632320404, 0.011581998318433762, 0.01189333200454712, 0.012204665690660477, 0.012516001239418983, 0.012827334925532341, 0.013138668611645699, 0.013450002297759056, 0.013761335983872414, 0.014072669669985771]}, "_timestamp": 1579762047.8386, "_step": 0}
