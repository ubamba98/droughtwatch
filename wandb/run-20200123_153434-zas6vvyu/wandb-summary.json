{"graph_0": {"_type": "graph", "edges": [], "nodes": [{"id": 139895809457792, "name": "conv_stem", "class_name": "Conv2dSame(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)", "parameters": [["weight", [40, 3, 3, 3]]], "output_shape": [[256, 40, 32, 32]], "num_parameters": [1080]}, {"id": 139895809881704, "name": "bn1", "class_name": "BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)", "parameters": [["weight", [40]], ["bias", [40]]], "output_shape": [[256, 40, 32, 32]], "num_parameters": [40, 40]}, {"id": 139895857205088, "name": "blocks.0.0", "class_name": "DepthwiseSeparableConv(\n  (conv_dw): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n  (bn1): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pw): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_dw.weight", [40, 1, 3, 3]], ["bn1.weight", [40]], ["bn1.bias", [40]], ["se.conv_reduce.weight", [10, 40, 1, 1]], ["se.conv_reduce.bias", [10]], ["se.conv_expand.weight", [40, 10, 1, 1]], ["se.conv_expand.bias", [40]], ["conv_pw.weight", [24, 40, 1, 1]], ["bn2.weight", [24]], ["bn2.bias", [24]]], "output_shape": [[256, 24, 32, 32]], "num_parameters": [360, 40, 40, 400, 10, 400, 40, 960, 24, 24]}, {"id": 139895809881984, "name": "blocks.0.1", "class_name": "DepthwiseSeparableConv(\n  (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n  (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_dw.weight", [24, 1, 3, 3]], ["bn1.weight", [24]], ["bn1.bias", [24]], ["se.conv_reduce.weight", [6, 24, 1, 1]], ["se.conv_reduce.bias", [6]], ["se.conv_expand.weight", [24, 6, 1, 1]], ["se.conv_expand.bias", [24]], ["conv_pw.weight", [24, 24, 1, 1]], ["bn2.weight", [24]], ["bn2.bias", [24]]], "output_shape": [[256, 24, 32, 32]], "num_parameters": [216, 24, 24, 144, 6, 144, 24, 576, 24, 24]}, {"id": 139895809880192, "name": "blocks.1.0", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n  (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [144, 24, 1, 1]], ["bn1.weight", [144]], ["bn1.bias", [144]], ["conv_dw.weight", [144, 1, 3, 3]], ["bn2.weight", [144]], ["bn2.bias", [144]], ["se.conv_reduce.weight", [6, 144, 1, 1]], ["se.conv_reduce.bias", [6]], ["se.conv_expand.weight", [144, 6, 1, 1]], ["se.conv_expand.bias", [144]], ["conv_pwl.weight", [32, 144, 1, 1]], ["bn3.weight", [32]], ["bn3.bias", [32]]], "output_shape": [[256, 32, 16, 16]], "num_parameters": [3456, 144, 144, 1296, 144, 144, 864, 6, 864, 144, 4608, 32, 32]}, {"id": 139895809881536, "name": "blocks.1.1", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n  (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [192, 32, 1, 1]], ["bn1.weight", [192]], ["bn1.bias", [192]], ["conv_dw.weight", [192, 1, 3, 3]], ["bn2.weight", [192]], ["bn2.bias", [192]], ["se.conv_reduce.weight", [8, 192, 1, 1]], ["se.conv_reduce.bias", [8]], ["se.conv_expand.weight", [192, 8, 1, 1]], ["se.conv_expand.bias", [192]], ["conv_pwl.weight", [32, 192, 1, 1]], ["bn3.weight", [32]], ["bn3.bias", [32]]], "output_shape": [[256, 32, 16, 16]], "num_parameters": [6144, 192, 192, 1728, 192, 192, 1536, 8, 1536, 192, 6144, 32, 32]}, {"id": 139895809882992, "name": "blocks.1.2", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n  (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [192, 32, 1, 1]], ["bn1.weight", [192]], ["bn1.bias", [192]], ["conv_dw.weight", [192, 1, 3, 3]], ["bn2.weight", [192]], ["bn2.bias", [192]], ["se.conv_reduce.weight", [8, 192, 1, 1]], ["se.conv_reduce.bias", [8]], ["se.conv_expand.weight", [192, 8, 1, 1]], ["se.conv_expand.bias", [192]], ["conv_pwl.weight", [32, 192, 1, 1]], ["bn3.weight", [32]], ["bn3.bias", [32]]], "output_shape": [[256, 32, 16, 16]], "num_parameters": [6144, 192, 192, 1728, 192, 192, 1536, 8, 1536, 192, 6144, 32, 32]}, {"id": 139895809883216, "name": "blocks.2.0", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(192, 192, kernel_size=(5, 5), stride=(2, 2), groups=192, bias=False)\n  (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [192, 32, 1, 1]], ["bn1.weight", [192]], ["bn1.bias", [192]], ["conv_dw.weight", [192, 1, 5, 5]], ["bn2.weight", [192]], ["bn2.bias", [192]], ["se.conv_reduce.weight", [8, 192, 1, 1]], ["se.conv_reduce.bias", [8]], ["se.conv_expand.weight", [192, 8, 1, 1]], ["se.conv_expand.bias", [192]], ["conv_pwl.weight", [48, 192, 1, 1]], ["bn3.weight", [48]], ["bn3.bias", [48]]], "output_shape": [[256, 48, 8, 8]], "num_parameters": [6144, 192, 192, 4800, 192, 192, 1536, 8, 1536, 192, 9216, 48, 48]}, {"id": 139895809880920, "name": "blocks.2.1", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n  (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [288, 48, 1, 1]], ["bn1.weight", [288]], ["bn1.bias", [288]], ["conv_dw.weight", [288, 1, 5, 5]], ["bn2.weight", [288]], ["bn2.bias", [288]], ["se.conv_reduce.weight", [12, 288, 1, 1]], ["se.conv_reduce.bias", [12]], ["se.conv_expand.weight", [288, 12, 1, 1]], ["se.conv_expand.bias", [288]], ["conv_pwl.weight", [48, 288, 1, 1]], ["bn3.weight", [48]], ["bn3.bias", [48]]], "output_shape": [[256, 48, 8, 8]], "num_parameters": [13824, 288, 288, 7200, 288, 288, 3456, 12, 3456, 288, 13824, 48, 48]}, {"id": 139895809881032, "name": "blocks.2.2", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n  (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [288, 48, 1, 1]], ["bn1.weight", [288]], ["bn1.bias", [288]], ["conv_dw.weight", [288, 1, 5, 5]], ["bn2.weight", [288]], ["bn2.bias", [288]], ["se.conv_reduce.weight", [12, 288, 1, 1]], ["se.conv_reduce.bias", [12]], ["se.conv_expand.weight", [288, 12, 1, 1]], ["se.conv_expand.bias", [288]], ["conv_pwl.weight", [48, 288, 1, 1]], ["bn3.weight", [48]], ["bn3.bias", [48]]], "output_shape": [[256, 48, 8, 8]], "num_parameters": [13824, 288, 288, 7200, 288, 288, 3456, 12, 3456, 288, 13824, 48, 48]}, {"id": 139895809740360, "name": "blocks.3.0", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(288, 288, kernel_size=(3, 3), stride=(2, 2), groups=288, bias=False)\n  (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [288, 48, 1, 1]], ["bn1.weight", [288]], ["bn1.bias", [288]], ["conv_dw.weight", [288, 1, 3, 3]], ["bn2.weight", [288]], ["bn2.bias", [288]], ["se.conv_reduce.weight", [12, 288, 1, 1]], ["se.conv_reduce.bias", [12]], ["se.conv_expand.weight", [288, 12, 1, 1]], ["se.conv_expand.bias", [288]], ["conv_pwl.weight", [96, 288, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [13824, 288, 288, 2592, 288, 288, 3456, 12, 3456, 288, 27648, 96, 96]}, {"id": 139895809740080, "name": "blocks.3.1", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"id": 139895809739856, "name": "blocks.3.2", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"id": 139895809737448, "name": "blocks.3.3", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"id": 139895809738624, "name": "blocks.3.4", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"id": 139895856512192, "name": "blocks.4.0", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 5, 5]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [136, 576, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [55296, 576, 576, 14400, 576, 576, 13824, 24, 13824, 576, 78336, 136, 136]}, {"id": 139895856510120, "name": "blocks.4.1", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"id": 139897892875680, "name": "blocks.4.2", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"id": 139895809456280, "name": "blocks.4.3", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"id": 139895809456616, "name": "blocks.4.4", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"id": 139895809731888, "name": "blocks.5.0", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(816, 816, kernel_size=(5, 5), stride=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [232, 816, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 189312, 232, 232]}, {"id": 139895809728752, "name": "blocks.5.1", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"id": 139895809730880, "name": "blocks.5.2", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"id": 139895809731720, "name": "blocks.5.3", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"id": 139895809730096, "name": "blocks.5.4", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"id": 139895809729312, "name": "blocks.5.5", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"id": 139895809934504, "name": "blocks.6.0", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 3, 3]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [384, 1392, 1, 1]], ["bn3.weight", [384]], ["bn3.bias", [384]]], "output_shape": [[256, 384, 2, 2]], "num_parameters": [322944, 1392, 1392, 12528, 1392, 1392, 80736, 58, 80736, 1392, 534528, 384, 384]}, {"id": 139895809936352, "name": "blocks.6.1", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n  (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [2304, 384, 1, 1]], ["bn1.weight", [2304]], ["bn1.bias", [2304]], ["conv_dw.weight", [2304, 1, 3, 3]], ["bn2.weight", [2304]], ["bn2.bias", [2304]], ["se.conv_reduce.weight", [96, 2304, 1, 1]], ["se.conv_reduce.bias", [96]], ["se.conv_expand.weight", [2304, 96, 1, 1]], ["se.conv_expand.bias", [2304]], ["conv_pwl.weight", [384, 2304, 1, 1]], ["bn3.weight", [384]], ["bn3.bias", [384]]], "output_shape": [[256, 384, 2, 2]], "num_parameters": [884736, 2304, 2304, 20736, 2304, 2304, 221184, 96, 221184, 2304, 884736, 384, 384]}, {"id": 139895809457904, "name": "conv_head", "class_name": "Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)", "parameters": [["weight", [1536, 384, 1, 1]]], "output_shape": [[256, 1536, 2, 2]], "num_parameters": [589824]}, {"id": 139895809936408, "name": "bn2", "class_name": "BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)", "parameters": [["weight", [1536]], ["bias", [1536]]], "output_shape": [[256, 1536, 2, 2]], "num_parameters": [1536, 1536]}, {"id": 139895809935904, "name": "global_pool", "class_name": "SelectAdaptivePool2d (output_size=1, pool_type=avg)", "parameters": [], "output_shape": [[256, 1536, 1, 1]], "num_parameters": []}, {"id": 139895809935736, "name": "classifier", "class_name": "Linear(in_features=1536, out_features=4, bias=True)", "parameters": [["weight", [4, 1536]], ["bias", [4]]], "output_shape": [[256, 4]], "num_parameters": [6144, 4]}], "format": "torch"}, "_timestamp": 1579795038.3345685, "gradients/classifier.bias": {"bins": [-0.048415496945381165, -0.04662719741463661, -0.04483889788389206, -0.04305059835314751, -0.041262298822402954, -0.0394739992916584, -0.03768569976091385, -0.035897396504879, -0.034109100699424744, -0.03232079744338989, -0.03053249977529049, -0.028744200244545937, -0.026955898851156235, -0.02516759932041168, -0.02337929978966713, -0.021591000258922577, -0.019802700728178024, -0.01801440119743347, -0.01622610166668892, -0.014437802135944366, -0.012649502605199814, -0.01086120307445526, -0.009072903543710709, -0.007284604012966156, -0.005496300756931305, -0.003708001226186752, -0.0019197016954421997, -0.0001314021646976471, 0.0016568973660469055, 0.003445196896791458, 0.005233496427536011, 0.007021795958280563, 0.008810095489025116, 0.010598395019769669, 0.01238669455051422, 0.014174997806549072, 0.015963293612003326, 0.017751596868038177, 0.01953989267349243, 0.021328195929527283, 0.023116491734981537, 0.024904794991016388, 0.02669309079647064, 0.028481394052505493, 0.030269689857959747, 0.0320579931139946, 0.03384628891944885, 0.035634592175483704, 0.037422895431518555, 0.03921119123697281, 0.04099949449300766, 0.042787790298461914, 0.044576093554496765, 0.04636438935995102, 0.04815269261598587, 0.04994098842144013, 0.051729291677474976, 0.05351758748292923, 0.05530589073896408, 0.057094186544418335, 0.058882489800453186, 0.06067078560590744, 0.06245908886194229, 0.06424738466739655, 0.0660356879234314], "_type": "histogram", "values": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}, "gradients/classifier.weight": {"bins": [-0.08897799998521805, -0.08625661581754684, -0.08353523164987564, -0.08081384748220444, -0.07809246331453323, -0.07537107914686203, -0.07264968752861023, -0.06992830336093903, -0.06720691919326782, -0.06448553502559662, -0.061764154583215714, -0.05904276669025421, -0.05632138252258301, -0.05359999835491181, -0.0508786141872406, -0.0481572300195694, -0.04543584585189819, -0.04271446168422699, -0.039993077516555786, -0.03727169334888458, -0.03455030918121338, -0.03182892128825188, -0.029107537120580673, -0.026386156678199768, -0.023664765059947968, -0.020943380892276764, -0.01822199672460556, -0.015500612556934357, -0.012779228389263151, -0.01005784422159195, -0.007336460053920746, -0.004615075886249542, -0.0018936917185783384, 0.000827692449092865, 0.0035490766167640686, 0.006270460784435272, 0.008991844952106476, 0.01171322911977768, 0.014434613287448885, 0.017155997455120087, 0.01987738162279129, 0.02259877324104309, 0.025320157408714294, 0.028041541576385495, 0.0307629257440567, 0.033484309911727905, 0.03620568662881851, 0.03892707079648971, 0.04164846986532211, 0.04436985403299332, 0.04709123820066452, 0.04981262236833573, 0.05253400653600693, 0.05525539070367813, 0.057976774871349335, 0.06069815903902054, 0.06341954320669174, 0.06614092737436295, 0.06886231154203415, 0.07158369570970535, 0.07430507987737656, 0.07702646404504776, 0.07974784821271896, 0.08246923238039017, 0.08519061654806137], "_type": "histogram", "values": [1, 0, 0, 0, 1, 2, 1, 4, 3, 7, 11, 16, 20, 16, 26, 29, 46, 64, 69, 70, 98, 121, 90, 155, 200, 201, 219, 247, 274, 273, 315, 303, 297, 302, 303, 272, 236, 271, 234, 206, 178, 169, 135, 153, 104, 80, 70, 59, 58, 23, 27, 15, 19, 13, 11, 8, 2, 6, 1, 4, 3, 0, 1, 2]}, "_step": 0, "_runtime": 1331.6014873981476, "val_acc": 0.7755082742316785}
