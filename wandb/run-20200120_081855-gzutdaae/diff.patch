diff --git a/Efficientnet-b3-765.ipynb b/Efficientnet-b3-765.ipynb
index 691c745..9cf4f55 100644
--- a/Efficientnet-b3-765.ipynb
+++ b/Efficientnet-b3-765.ipynb
@@ -47,7 +47,7 @@
        "\n",
        "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
        "                Project page: <a href=\"https://app.wandb.ai/ubamba98/droughtwatch\" target=\"_blank\">https://app.wandb.ai/ubamba98/droughtwatch</a><br/>\n",
-       "                Run page: <a href=\"https://app.wandb.ai/ubamba98/droughtwatch/runs/j9gqs3hm\" target=\"_blank\">https://app.wandb.ai/ubamba98/droughtwatch/runs/j9gqs3hm</a><br/>\n",
+       "                Run page: <a href=\"https://app.wandb.ai/ubamba98/droughtwatch/runs/gzutdaae\" target=\"_blank\">https://app.wandb.ai/ubamba98/droughtwatch/runs/gzutdaae</a><br/>\n",
        "            "
       ],
       "text/plain": [
@@ -67,7 +67,7 @@
     {
      "data": {
       "text/plain": [
-       "W&B Run: https://app.wandb.ai/ubamba98/droughtwatch/runs/j9gqs3hm"
+       "W&B Run: https://app.wandb.ai/ubamba98/droughtwatch/runs/gzutdaae"
       ]
      },
      "execution_count": 2,
@@ -77,7 +77,16 @@
    ],
    "source": [
     "import wandb\n",
-    "wandb.init(project=\"droughtwatch\")"
+    "wandb.init(project='droughtwatch', name='efficentnet-b3-765')"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 3,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "os.environ['WANDB_NOTEBOOK_NAME'] = \"efficentnet-b3-765\""
    ]
   },
   {
@@ -89,7 +98,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 4,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -112,7 +121,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 5,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -147,7 +156,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 6,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -188,7 +197,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
+   "execution_count": 7,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -226,7 +235,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": 8,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -244,7 +253,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 9,
    "metadata": {},
    "outputs": [
     {
@@ -584,7 +593,7 @@
        ")"
       ]
      },
-     "execution_count": 8,
+     "execution_count": 9,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -597,16 +606,16 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 10,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [
-       "[<wandb.wandb_torch.TorchGraph at 0x7f4ae970e6d8>]"
+       "[<wandb.wandb_torch.TorchGraph at 0x7fba6796b390>]"
       ]
      },
-     "execution_count": 9,
+     "execution_count": 10,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -624,7 +633,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
+   "execution_count": 11,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -651,57 +660,20 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 11,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "class ImageDataset(Dataset):\n",
-    "        \n",
-    "    def __init__(self, transform=None, limit=None, mode = \"train\", train_dir=\"train\", val_dir=\"val\", weights = [1, 1, 1, 1]):\n",
-    "        \n",
-    "        self.transform = transform\n",
-    "        self.limit = limit\n",
-    "        self.mode = mode\n",
-    "        self.train_dir = train_dir\n",
-    "        self.val_dir = val_dir\n",
-    "        self.train_files=[]\n",
-    "        for i in range(4):\n",
-    "            self.train_files += glob.glob(self.train_dir+\"/*\"+str(i)+\"/*\") * weights[i]\n",
-    "        self.val_files=glob.glob(self.val_dir+\"/*/*\")\n",
-    "        self.train_sample_count = len(self.train_files)\n",
-    "        self.val_sample_count = len(self.val_files)\n",
-    "        \n",
-    "    def __len__(self):\n",
-    "        if self.mode == \"train\":\n",
-    "            return (self.train_sample_count)\n",
-    "        else:\n",
-    "            return(self.val_sample_count)\n",
-    "\n",
-    "    def __getitem__(self, idx): \n",
-    "        if self.mode == \"train\":\n",
-    "            return (self.get_img(self.train_files[idx]), int(self.train_files[idx].split('/')[-2].split(\"_\")[-1]))\n",
-    "        if self.mode == \"val\":\n",
-    "            return (self.get_img(self.val_files[idx]), int(self.val_files[idx].split('/')[-2].split(\"_\")[-1]))\n",
-    "        \n",
-    "    def get_img(self, img_dir):\n",
-    "        img = np.load(img_dir)\n",
-    "        #img = img.transpose((1, 2, 0))\n",
-    "        img = img[:, :, [6, 5, 4]] ## Select for channels to run\n",
-    "        img = self.transform(img)\n",
-    "        img = torch.from_numpy(np.moveaxis(img, -1, 0)).float()  \n",
-    "        return img"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 12,
+   "execution_count": 14,
    "metadata": {},
    "outputs": [
     {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "{'train': 799, 'val': 331}\n"
+     "ename": "ValueError",
+     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
+      "\u001b[0;32m<ipython-input-14-06a69a7d0d7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             )\n\u001b[1;32m      9\u001b[0m valid_loader = DataLoader(\n",
+      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             raise ValueError(\"num_samples should be a positive integer \"\n\u001b[0;32m---> 94\u001b[0;31m                              \"value, but got num_samples={}\".format(self.num_samples))\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
      ]
     }
    ],
