{"graph_0": {"_type": "graph", "format": "torch", "nodes": [{"name": "conv_stem", "id": 140438557381128, "class_name": "Conv2dSame(3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)", "parameters": [["weight", [40, 3, 3, 3]]], "output_shape": [[256, 40, 32, 32]], "num_parameters": [1080]}, {"name": "bn1", "id": 140438557383704, "class_name": "BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)", "parameters": [["weight", [40]], ["bias", [40]]], "output_shape": [[256, 40, 32, 32]], "num_parameters": [40, 40]}, {"name": "blocks.0.0", "id": 140438557382920, "class_name": "DepthwiseSeparableConv(\n  (conv_dw): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n  (bn1): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pw): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_dw.weight", [40, 1, 3, 3]], ["bn1.weight", [40]], ["bn1.bias", [40]], ["se.conv_reduce.weight", [10, 40, 1, 1]], ["se.conv_reduce.bias", [10]], ["se.conv_expand.weight", [40, 10, 1, 1]], ["se.conv_expand.bias", [40]], ["conv_pw.weight", [24, 40, 1, 1]], ["bn2.weight", [24]], ["bn2.bias", [24]]], "output_shape": [[256, 24, 32, 32]], "num_parameters": [360, 40, 40, 400, 10, 400, 40, 960, 24, 24]}, {"name": "blocks.0.1", "id": 140438680665224, "class_name": "DepthwiseSeparableConv(\n  (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n  (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_dw.weight", [24, 1, 3, 3]], ["bn1.weight", [24]], ["bn1.bias", [24]], ["se.conv_reduce.weight", [6, 24, 1, 1]], ["se.conv_reduce.bias", [6]], ["se.conv_expand.weight", [24, 6, 1, 1]], ["se.conv_expand.bias", [24]], ["conv_pw.weight", [24, 24, 1, 1]], ["bn2.weight", [24]], ["bn2.bias", [24]]], "output_shape": [[256, 24, 32, 32]], "num_parameters": [216, 24, 24, 144, 6, 144, 24, 576, 24, 24]}, {"name": "blocks.1.0", "id": 140438676598736, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n  (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [144, 24, 1, 1]], ["bn1.weight", [144]], ["bn1.bias", [144]], ["conv_dw.weight", [144, 1, 3, 3]], ["bn2.weight", [144]], ["bn2.bias", [144]], ["se.conv_reduce.weight", [6, 144, 1, 1]], ["se.conv_reduce.bias", [6]], ["se.conv_expand.weight", [144, 6, 1, 1]], ["se.conv_expand.bias", [144]], ["conv_pwl.weight", [32, 144, 1, 1]], ["bn3.weight", [32]], ["bn3.bias", [32]]], "output_shape": [[256, 32, 16, 16]], "num_parameters": [3456, 144, 144, 1296, 144, 144, 864, 6, 864, 144, 4608, 32, 32]}, {"name": "blocks.1.1", "id": 140438557424160, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n  (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [192, 32, 1, 1]], ["bn1.weight", [192]], ["bn1.bias", [192]], ["conv_dw.weight", [192, 1, 3, 3]], ["bn2.weight", [192]], ["bn2.bias", [192]], ["se.conv_reduce.weight", [8, 192, 1, 1]], ["se.conv_reduce.bias", [8]], ["se.conv_expand.weight", [192, 8, 1, 1]], ["se.conv_expand.bias", [192]], ["conv_pwl.weight", [32, 192, 1, 1]], ["bn3.weight", [32]], ["bn3.bias", [32]]], "output_shape": [[256, 32, 16, 16]], "num_parameters": [6144, 192, 192, 1728, 192, 192, 1536, 8, 1536, 192, 6144, 32, 32]}, {"name": "blocks.1.2", "id": 140438679559640, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n  (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [192, 32, 1, 1]], ["bn1.weight", [192]], ["bn1.bias", [192]], ["conv_dw.weight", [192, 1, 3, 3]], ["bn2.weight", [192]], ["bn2.bias", [192]], ["se.conv_reduce.weight", [8, 192, 1, 1]], ["se.conv_reduce.bias", [8]], ["se.conv_expand.weight", [192, 8, 1, 1]], ["se.conv_expand.bias", [192]], ["conv_pwl.weight", [32, 192, 1, 1]], ["bn3.weight", [32]], ["bn3.bias", [32]]], "output_shape": [[256, 32, 16, 16]], "num_parameters": [6144, 192, 192, 1728, 192, 192, 1536, 8, 1536, 192, 6144, 32, 32]}, {"name": "blocks.2.0", "id": 140438679470320, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(192, 192, kernel_size=(5, 5), stride=(2, 2), groups=192, bias=False)\n  (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [192, 32, 1, 1]], ["bn1.weight", [192]], ["bn1.bias", [192]], ["conv_dw.weight", [192, 1, 5, 5]], ["bn2.weight", [192]], ["bn2.bias", [192]], ["se.conv_reduce.weight", [8, 192, 1, 1]], ["se.conv_reduce.bias", [8]], ["se.conv_expand.weight", [192, 8, 1, 1]], ["se.conv_expand.bias", [192]], ["conv_pwl.weight", [48, 192, 1, 1]], ["bn3.weight", [48]], ["bn3.bias", [48]]], "output_shape": [[256, 48, 8, 8]], "num_parameters": [6144, 192, 192, 4800, 192, 192, 1536, 8, 1536, 192, 9216, 48, 48]}, {"name": "blocks.2.1", "id": 140438557424384, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n  (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [288, 48, 1, 1]], ["bn1.weight", [288]], ["bn1.bias", [288]], ["conv_dw.weight", [288, 1, 5, 5]], ["bn2.weight", [288]], ["bn2.bias", [288]], ["se.conv_reduce.weight", [12, 288, 1, 1]], ["se.conv_reduce.bias", [12]], ["se.conv_expand.weight", [288, 12, 1, 1]], ["se.conv_expand.bias", [288]], ["conv_pwl.weight", [48, 288, 1, 1]], ["bn3.weight", [48]], ["bn3.bias", [48]]], "output_shape": [[256, 48, 8, 8]], "num_parameters": [13824, 288, 288, 7200, 288, 288, 3456, 12, 3456, 288, 13824, 48, 48]}, {"name": "blocks.2.2", "id": 140438557422704, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n  (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [288, 48, 1, 1]], ["bn1.weight", [288]], ["bn1.bias", [288]], ["conv_dw.weight", [288, 1, 5, 5]], ["bn2.weight", [288]], ["bn2.bias", [288]], ["se.conv_reduce.weight", [12, 288, 1, 1]], ["se.conv_reduce.bias", [12]], ["se.conv_expand.weight", [288, 12, 1, 1]], ["se.conv_expand.bias", [288]], ["conv_pwl.weight", [48, 288, 1, 1]], ["bn3.weight", [48]], ["bn3.bias", [48]]], "output_shape": [[256, 48, 8, 8]], "num_parameters": [13824, 288, 288, 7200, 288, 288, 3456, 12, 3456, 288, 13824, 48, 48]}, {"name": "blocks.3.0", "id": 140438557421920, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(288, 288, kernel_size=(3, 3), stride=(2, 2), groups=288, bias=False)\n  (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [288, 48, 1, 1]], ["bn1.weight", [288]], ["bn1.bias", [288]], ["conv_dw.weight", [288, 1, 3, 3]], ["bn2.weight", [288]], ["bn2.bias", [288]], ["se.conv_reduce.weight", [12, 288, 1, 1]], ["se.conv_reduce.bias", [12]], ["se.conv_expand.weight", [288, 12, 1, 1]], ["se.conv_expand.bias", [288]], ["conv_pwl.weight", [96, 288, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [13824, 288, 288, 2592, 288, 288, 3456, 12, 3456, 288, 27648, 96, 96]}, {"name": "blocks.3.1", "id": 140438557422816, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"name": "blocks.3.2", "id": 140438557824392, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"name": "blocks.3.3", "id": 140438557825232, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"name": "blocks.3.4", "id": 140438557825176, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"name": "blocks.4.0", "id": 140438557824672, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 5, 5]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [136, 576, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [55296, 576, 576, 14400, 576, 576, 13824, 24, 13824, 576, 78336, 136, 136]}, {"name": "blocks.4.1", "id": 140438557823496, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"name": "blocks.4.2", "id": 140438679158968, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"name": "blocks.4.3", "id": 140438679496744, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"name": "blocks.4.4", "id": 140438679422456, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"name": "blocks.5.0", "id": 140438679421448, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(816, 816, kernel_size=(5, 5), stride=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [232, 816, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 189312, 232, 232]}, {"name": "blocks.5.1", "id": 140438679580400, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"name": "blocks.5.2", "id": 140438679115088, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"name": "blocks.5.3", "id": 140438676984832, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"name": "blocks.5.4", "id": 140440670709296, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"name": "blocks.5.5", "id": 140440670710192, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"name": "blocks.6.0", "id": 140440670709464, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 3, 3]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [384, 1392, 1, 1]], ["bn3.weight", [384]], ["bn3.bias", [384]]], "output_shape": [[256, 384, 2, 2]], "num_parameters": [322944, 1392, 1392, 12528, 1392, 1392, 80736, 58, 80736, 1392, 534528, 384, 384]}, {"name": "blocks.6.1", "id": 140438679947864, "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n  (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [2304, 384, 1, 1]], ["bn1.weight", [2304]], ["bn1.bias", [2304]], ["conv_dw.weight", [2304, 1, 3, 3]], ["bn2.weight", [2304]], ["bn2.bias", [2304]], ["se.conv_reduce.weight", [96, 2304, 1, 1]], ["se.conv_reduce.bias", [96]], ["se.conv_expand.weight", [2304, 96, 1, 1]], ["se.conv_expand.bias", [2304]], ["conv_pwl.weight", [384, 2304, 1, 1]], ["bn3.weight", [384]], ["bn3.bias", [384]]], "output_shape": [[256, 384, 2, 2]], "num_parameters": [884736, 2304, 2304, 20736, 2304, 2304, 221184, 96, 221184, 2304, 884736, 384, 384]}, {"name": "conv_head", "id": 140438557382584, "class_name": "Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)", "parameters": [["weight", [1536, 384, 1, 1]]], "output_shape": [[256, 1536, 2, 2]], "num_parameters": [589824]}, {"name": "bn2", "id": 140438703610848, "class_name": "BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)", "parameters": [["weight", [1536]], ["bias", [1536]]], "output_shape": [[256, 1536, 2, 2]], "num_parameters": [1536, 1536]}, {"name": "global_pool", "id": 140438703610792, "class_name": "SelectAdaptivePool2d (output_size=1, pool_type=avg)", "parameters": [], "output_shape": [[256, 1536, 1, 1]], "num_parameters": []}, {"name": "classifier", "id": 140438679885696, "class_name": "Linear(in_features=1536, out_features=4, bias=True)", "parameters": [["weight", [4, 1536]], ["bias", [4]]], "output_shape": [[256, 4]], "num_parameters": [6144, 4]}], "edges": []}, "train_acc": 0.25812953441384673, "_step": 0, "gradients/classifier.weight": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 5.0, 2.0, 4.0, 10.0, 9.0, 17.0, 15.0, 21.0, 30.0, 49.0, 53.0, 61.0, 86.0, 96.0, 118.0, 155.0, 170.0, 210.0, 214.0, 249.0, 229.0, 254.0, 272.0, 299.0, 314.0, 295.0, 344.0, 291.0, 277.0, 262.0, 259.0, 239.0, 186.0, 184.0, 169.0, 136.0, 111.0, 97.0, 83.0, 60.0, 47.0, 38.0, 19.0, 23.0, 20.0, 13.0, 17.0, 7.0, 8.0, 4.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.09012244641780853, -0.08724749088287354, -0.08437253534793854, -0.08149757981300354, -0.07862262427806854, -0.07574766874313354, -0.07287271320819855, -0.06999775767326355, -0.06712280213832855, -0.06424784660339355, -0.06137289106845856, -0.05849793553352356, -0.05562297999858856, -0.052748024463653564, -0.04987306892871857, -0.04699811339378357, -0.04412315785884857, -0.041248202323913574, -0.03837324678897858, -0.03549829125404358, -0.03262333571910858, -0.029748380184173584, -0.026873424649238586, -0.02399846911430359, -0.02112351357936859, -0.018248558044433594, -0.015373602509498596, -0.012498646974563599, -0.009623691439628601, -0.0067487359046936035, -0.003873780369758606, -0.0009988248348236084, 0.0018761307001113892, 0.004751086235046387, 0.007626041769981384, 0.010500997304916382, 0.01337595283985138, 0.016250908374786377, 0.019125863909721375, 0.022000819444656372, 0.02487577497959137, 0.027750730514526367, 0.030625686049461365, 0.03350064158439636, 0.03637559711933136, 0.03925055265426636, 0.042125508189201355, 0.04500046372413635, 0.04787541925907135, 0.05075037479400635, 0.053625330328941345, 0.05650028586387634, 0.05937524139881134, 0.06225019693374634, 0.06512515246868134, 0.06800010800361633, 0.07087506353855133, 0.07375001907348633, 0.07662497460842133, 0.07949993014335632, 0.08237488567829132, 0.08524984121322632, 0.08812479674816132, 0.09099975228309631, 0.09387470781803131]}, "gradients/classifier.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0654682070016861, -0.06339701265096664, -0.06132581830024719, -0.05925462394952774, -0.05718342587351799, -0.05511223152279854, -0.053041037172079086, -0.050969842821359634, -0.048898644745349884, -0.04682745039463043, -0.04475625604391098, -0.04268506169319153, -0.040613867342472076, -0.038542672991752625, -0.03647147864103317, -0.03440028056502342, -0.03232908621430397, -0.03025789186358452, -0.028186697512865067, -0.026115499436855316, -0.024044305086135864, -0.021973110735416412, -0.01990191638469696, -0.01783072203397751, -0.015759527683258057, -0.013688329607248306, -0.011617135256528854, -0.009545940905809402, -0.0074747465550899506, -0.005403552204370499, -0.0033323541283607483, -0.0012611597776412964, 0.0008100345730781555, 0.0028812289237976074, 0.004952423274517059, 0.007023617625236511, 0.009094811975955963, 0.011166006326675415, 0.013237208127975464, 0.015308402478694916, 0.017379596829414368, 0.01945079118013382, 0.02152198553085327, 0.023593179881572723, 0.025664374232292175, 0.027735568583011627, 0.02980676293373108, 0.03187795728445053, 0.03394915163516998, 0.03602035343647003, 0.038091547787189484, 0.040162742137908936, 0.04223393648862839, 0.04430513083934784, 0.04637632519006729, 0.04844751954078674, 0.050518713891506195, 0.05258990824222565, 0.0546611025929451, 0.05673230439424515, 0.0588034987449646, 0.060874685645103455, 0.0629458874464035, 0.06501707434654236, 0.06708827614784241]}, "val_acc": 0.23687943262411348, "_runtime": 814.0969541072845, "_timestamp": 1579509224.6157851}
