{"graph_0": {"_type": "graph", "edges": [], "nodes": [{"id": 140303489784240, "name": "conv_stem", "class_name": "Conv2dSame(7, 40, kernel_size=(3, 3), stride=(2, 2), bias=False)", "parameters": [["weight", [40, 7, 3, 3]]], "output_shape": [[256, 40, 32, 32]], "num_parameters": [2520]}, {"id": 140303443086416, "name": "bn1", "class_name": "BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)", "parameters": [["weight", [40]], ["bias", [40]]], "output_shape": [[256, 40, 32, 32]], "num_parameters": [40, 40]}, {"id": 140303489784520, "name": "blocks.0.0", "class_name": "DepthwiseSeparableConv(\n  (conv_dw): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n  (bn1): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pw): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_dw.weight", [40, 1, 3, 3]], ["bn1.weight", [40]], ["bn1.bias", [40]], ["se.conv_reduce.weight", [10, 40, 1, 1]], ["se.conv_reduce.bias", [10]], ["se.conv_expand.weight", [40, 10, 1, 1]], ["se.conv_expand.bias", [40]], ["conv_pw.weight", [24, 40, 1, 1]], ["bn2.weight", [24]], ["bn2.bias", [24]]], "output_shape": [[256, 24, 32, 32]], "num_parameters": [360, 40, 40, 400, 10, 400, 40, 960, 24, 24]}, {"id": 140303489782336, "name": "blocks.0.1", "class_name": "DepthwiseSeparableConv(\n  (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n  (bn1): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn2): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_dw.weight", [24, 1, 3, 3]], ["bn1.weight", [24]], ["bn1.bias", [24]], ["se.conv_reduce.weight", [6, 24, 1, 1]], ["se.conv_reduce.bias", [6]], ["se.conv_expand.weight", [24, 6, 1, 1]], ["se.conv_expand.bias", [24]], ["conv_pw.weight", [24, 24, 1, 1]], ["bn2.weight", [24]], ["bn2.bias", [24]]], "output_shape": [[256, 24, 32, 32]], "num_parameters": [216, 24, 24, 144, 6, 144, 24, 576, 24, 24]}, {"id": 140303443083392, "name": "blocks.1.0", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n  (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [144, 24, 1, 1]], ["bn1.weight", [144]], ["bn1.bias", [144]], ["conv_dw.weight", [144, 1, 3, 3]], ["bn2.weight", [144]], ["bn2.bias", [144]], ["se.conv_reduce.weight", [6, 144, 1, 1]], ["se.conv_reduce.bias", [6]], ["se.conv_expand.weight", [144, 6, 1, 1]], ["se.conv_expand.bias", [144]], ["conv_pwl.weight", [32, 144, 1, 1]], ["bn3.weight", [32]], ["bn3.bias", [32]]], "output_shape": [[256, 32, 16, 16]], "num_parameters": [3456, 144, 144, 1296, 144, 144, 864, 6, 864, 144, 4608, 32, 32]}, {"id": 140303443085912, "name": "blocks.1.1", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n  (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [192, 32, 1, 1]], ["bn1.weight", [192]], ["bn1.bias", [192]], ["conv_dw.weight", [192, 1, 3, 3]], ["bn2.weight", [192]], ["bn2.bias", [192]], ["se.conv_reduce.weight", [8, 192, 1, 1]], ["se.conv_reduce.bias", [8]], ["se.conv_expand.weight", [192, 8, 1, 1]], ["se.conv_expand.bias", [192]], ["conv_pwl.weight", [32, 192, 1, 1]], ["bn3.weight", [32]], ["bn3.bias", [32]]], "output_shape": [[256, 32, 16, 16]], "num_parameters": [6144, 192, 192, 1728, 192, 192, 1536, 8, 1536, 192, 6144, 32, 32]}, {"id": 140303489783624, "name": "blocks.1.2", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n  (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [192, 32, 1, 1]], ["bn1.weight", [192]], ["bn1.bias", [192]], ["conv_dw.weight", [192, 1, 3, 3]], ["bn2.weight", [192]], ["bn2.bias", [192]], ["se.conv_reduce.weight", [8, 192, 1, 1]], ["se.conv_reduce.bias", [8]], ["se.conv_expand.weight", [192, 8, 1, 1]], ["se.conv_expand.bias", [192]], ["conv_pwl.weight", [32, 192, 1, 1]], ["bn3.weight", [32]], ["bn3.bias", [32]]], "output_shape": [[256, 32, 16, 16]], "num_parameters": [6144, 192, 192, 1728, 192, 192, 1536, 8, 1536, 192, 6144, 32, 32]}, {"id": 140303489782000, "name": "blocks.2.0", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(192, 192, kernel_size=(5, 5), stride=(2, 2), groups=192, bias=False)\n  (bn2): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [192, 32, 1, 1]], ["bn1.weight", [192]], ["bn1.bias", [192]], ["conv_dw.weight", [192, 1, 5, 5]], ["bn2.weight", [192]], ["bn2.bias", [192]], ["se.conv_reduce.weight", [8, 192, 1, 1]], ["se.conv_reduce.bias", [8]], ["se.conv_expand.weight", [192, 8, 1, 1]], ["se.conv_expand.bias", [192]], ["conv_pwl.weight", [48, 192, 1, 1]], ["bn3.weight", [48]], ["bn3.bias", [48]]], "output_shape": [[256, 48, 8, 8]], "num_parameters": [6144, 192, 192, 4800, 192, 192, 1536, 8, 1536, 192, 9216, 48, 48]}, {"id": 140303489782448, "name": "blocks.2.1", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n  (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [288, 48, 1, 1]], ["bn1.weight", [288]], ["bn1.bias", [288]], ["conv_dw.weight", [288, 1, 5, 5]], ["bn2.weight", [288]], ["bn2.bias", [288]], ["se.conv_reduce.weight", [12, 288, 1, 1]], ["se.conv_reduce.bias", [12]], ["se.conv_expand.weight", [288, 12, 1, 1]], ["se.conv_expand.bias", [288]], ["conv_pwl.weight", [48, 288, 1, 1]], ["bn3.weight", [48]], ["bn3.bias", [48]]], "output_shape": [[256, 48, 8, 8]], "num_parameters": [13824, 288, 288, 7200, 288, 288, 3456, 12, 3456, 288, 13824, 48, 48]}, {"id": 140303489803880, "name": "blocks.2.2", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n  (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [288, 48, 1, 1]], ["bn1.weight", [288]], ["bn1.bias", [288]], ["conv_dw.weight", [288, 1, 5, 5]], ["bn2.weight", [288]], ["bn2.bias", [288]], ["se.conv_reduce.weight", [12, 288, 1, 1]], ["se.conv_reduce.bias", [12]], ["se.conv_expand.weight", [288, 12, 1, 1]], ["se.conv_expand.bias", [288]], ["conv_pwl.weight", [48, 288, 1, 1]], ["bn3.weight", [48]], ["bn3.bias", [48]]], "output_shape": [[256, 48, 8, 8]], "num_parameters": [13824, 288, 288, 7200, 288, 288, 3456, 12, 3456, 288, 13824, 48, 48]}, {"id": 140303489805280, "name": "blocks.3.0", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(288, 288, kernel_size=(3, 3), stride=(2, 2), groups=288, bias=False)\n  (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [288, 48, 1, 1]], ["bn1.weight", [288]], ["bn1.bias", [288]], ["conv_dw.weight", [288, 1, 3, 3]], ["bn2.weight", [288]], ["bn2.bias", [288]], ["se.conv_reduce.weight", [12, 288, 1, 1]], ["se.conv_reduce.bias", [12]], ["se.conv_expand.weight", [288, 12, 1, 1]], ["se.conv_expand.bias", [288]], ["conv_pwl.weight", [96, 288, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [13824, 288, 288, 2592, 288, 288, 3456, 12, 3456, 288, 27648, 96, 96]}, {"id": 140303489804440, "name": "blocks.3.1", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"id": 140303490046888, "name": "blocks.3.2", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"id": 140303442934864, "name": "blocks.3.3", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"id": 140303442933296, "name": "blocks.3.4", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 3, 3]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [96, 576, 1, 1]], ["bn3.weight", [96]], ["bn3.bias", [96]]], "output_shape": [[256, 96, 4, 4]], "num_parameters": [55296, 576, 576, 5184, 576, 576, 13824, 24, 13824, 576, 55296, 96, 96]}, {"id": 140303442934472, "name": "blocks.4.0", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n  (bn2): BatchNorm2d(576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [576, 96, 1, 1]], ["bn1.weight", [576]], ["bn1.bias", [576]], ["conv_dw.weight", [576, 1, 5, 5]], ["bn2.weight", [576]], ["bn2.bias", [576]], ["se.conv_reduce.weight", [24, 576, 1, 1]], ["se.conv_reduce.bias", [24]], ["se.conv_expand.weight", [576, 24, 1, 1]], ["se.conv_expand.bias", [576]], ["conv_pwl.weight", [136, 576, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [55296, 576, 576, 14400, 576, 576, 13824, 24, 13824, 576, 78336, 136, 136]}, {"id": 140303442934976, "name": "blocks.4.1", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"id": 140303442933352, "name": "blocks.4.2", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"id": 140303442934304, "name": "blocks.4.3", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"id": 140303443039960, "name": "blocks.4.4", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(136, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [136, 816, 1, 1]], ["bn3.weight", [136]], ["bn3.bias", [136]]], "output_shape": [[256, 136, 4, 4]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 110976, 136, 136]}, {"id": 140303443040072, "name": "blocks.5.0", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2dSame(816, 816, kernel_size=(5, 5), stride=(2, 2), groups=816, bias=False)\n  (bn2): BatchNorm2d(816, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [816, 136, 1, 1]], ["bn1.weight", [816]], ["bn1.bias", [816]], ["conv_dw.weight", [816, 1, 5, 5]], ["bn2.weight", [816]], ["bn2.bias", [816]], ["se.conv_reduce.weight", [34, 816, 1, 1]], ["se.conv_reduce.bias", [34]], ["se.conv_expand.weight", [816, 34, 1, 1]], ["se.conv_expand.bias", [816]], ["conv_pwl.weight", [232, 816, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [110976, 816, 816, 20400, 816, 816, 27744, 34, 27744, 816, 189312, 232, 232]}, {"id": 140303443040800, "name": "blocks.5.1", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"id": 140303443041472, "name": "blocks.5.2", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"id": 140303443042032, "name": "blocks.5.3", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"id": 140303649247864, "name": "blocks.5.4", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"id": 140305509271032, "name": "blocks.5.5", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(232, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 5, 5]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [232, 1392, 1, 1]], ["bn3.weight", [232]], ["bn3.bias", [232]]], "output_shape": [[256, 232, 2, 2]], "num_parameters": [322944, 1392, 1392, 34800, 1392, 1392, 80736, 58, 80736, 1392, 322944, 232, 232]}, {"id": 140303465713904, "name": "blocks.6.0", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n  (bn2): BatchNorm2d(1392, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [1392, 232, 1, 1]], ["bn1.weight", [1392]], ["bn1.bias", [1392]], ["conv_dw.weight", [1392, 1, 3, 3]], ["bn2.weight", [1392]], ["bn2.bias", [1392]], ["se.conv_reduce.weight", [58, 1392, 1, 1]], ["se.conv_reduce.bias", [58]], ["se.conv_expand.weight", [1392, 58, 1, 1]], ["se.conv_expand.bias", [1392]], ["conv_pwl.weight", [384, 1392, 1, 1]], ["bn3.weight", [384]], ["bn3.bias", [384]]], "output_shape": [[256, 384, 2, 2]], "num_parameters": [322944, 1392, 1392, 12528, 1392, 1392, 80736, 58, 80736, 1392, 534528, 384, 384]}, {"id": 140303465714800, "name": "blocks.6.1", "class_name": "InvertedResidual(\n  (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n  (bn2): BatchNorm2d(2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (se): SqueezeExcite(\n    (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n    (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn3): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n)", "parameters": [["conv_pw.weight", [2304, 384, 1, 1]], ["bn1.weight", [2304]], ["bn1.bias", [2304]], ["conv_dw.weight", [2304, 1, 3, 3]], ["bn2.weight", [2304]], ["bn2.bias", [2304]], ["se.conv_reduce.weight", [96, 2304, 1, 1]], ["se.conv_reduce.bias", [96]], ["se.conv_expand.weight", [2304, 96, 1, 1]], ["se.conv_expand.bias", [2304]], ["conv_pwl.weight", [384, 2304, 1, 1]], ["bn3.weight", [384]], ["bn3.bias", [384]]], "output_shape": [[256, 384, 2, 2]], "num_parameters": [884736, 2304, 2304, 20736, 2304, 2304, 221184, 96, 221184, 2304, 884736, 384, 384]}, {"id": 140303489783736, "name": "conv_head", "class_name": "Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)", "parameters": [["weight", [1536, 384, 1, 1]]], "output_shape": [[256, 1536, 2, 2]], "num_parameters": [589824]}, {"id": 140303465715864, "name": "bn2", "class_name": "BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)", "parameters": [["weight", [1536]], ["bias", [1536]]], "output_shape": [[256, 1536, 2, 2]], "num_parameters": [1536, 1536]}, {"id": 140303465715920, "name": "global_pool", "class_name": "SelectAdaptivePool2d (output_size=1, pool_type=avg)", "parameters": [], "output_shape": [[256, 1536, 1, 1]], "num_parameters": []}, {"id": 140303465716032, "name": "classifier", "class_name": "Linear(in_features=1536, out_features=4, bias=True)", "parameters": [["weight", [4, 1536]], ["bias", [4]]], "output_shape": [[256, 4]], "num_parameters": [6144, 4]}], "format": "torch"}, "gradients/classifier.bias": {"bins": [-0.03505779057741165, -0.03320246562361717, -0.03134714066982269, -0.029491817578673363, -0.027636494487524033, -0.025781169533729553, -0.02392584457993507, -0.022070521488785744, -0.020215198397636417, -0.018359873443841938, -0.016504548490047455, -0.014649225398898125, -0.012793900445103644, -0.010938577353954315, -0.009083252400159836, -0.007227929309010506, -0.005372604355216026, -0.003517281264066696, -0.0016619563102722168, 0.00019336864352226257, 0.002048693597316742, 0.003904014825820923, 0.005759339779615402, 0.007614664733409882, 0.00946998968720436, 0.01132531464099884, 0.01318063586950302, 0.0150359608232975, 0.01689128577709198, 0.01874661073088646, 0.02060193195939064, 0.02245725691318512, 0.0243125818669796, 0.02616790682077408, 0.02802322804927826, 0.029878556728363037, 0.03173387795686722, 0.0335891991853714, 0.03544452786445618, 0.03729984909296036, 0.039155177772045135, 0.04101049900054931, 0.0428658202290535, 0.044721148908138275, 0.046576470136642456, 0.048431798815727234, 0.050287120044231415, 0.0521424412727356, 0.053997769951820374, 0.055853091180324554, 0.05770841985940933, 0.05956374108791351, 0.061419062316417694, 0.06327439099550247, 0.06512971222400665, 0.06698503345251083, 0.06884036213159561, 0.07069568336009979, 0.07255101203918457, 0.07440633326768875, 0.07626165449619293, 0.07811698317527771, 0.07997230440378189, 0.08182763308286667, 0.08368295431137085], "_type": "histogram", "values": [1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}, "_timestamp": 1579715816.424449, "_step": 0, "gradients/classifier.weight": {"bins": [-0.09467010200023653, -0.09191536158323288, -0.08916062116622925, -0.08640588819980621, -0.08365114778280258, -0.08089640736579895, -0.07814167439937592, -0.07538693398237228, -0.07263219356536865, -0.06987745314836502, -0.06712271273136139, -0.06436797976493835, -0.06161323934793472, -0.05885849893093109, -0.05610376223921776, -0.053349025547504425, -0.05059428513050079, -0.04783954471349716, -0.04508480802178383, -0.042330071330070496, -0.039575330913066864, -0.03682059049606323, -0.0340658538043499, -0.031311117112636566, -0.028556376695632935, -0.025801636278629303, -0.02304689586162567, -0.020292162895202637, -0.017537422478199005, -0.014782682061195374, -0.01202794909477234, -0.009273208677768707, -0.006518468260765076, -0.003763727843761444, -0.0010089874267578125, 0.0017457455396652222, 0.004500485956668854, 0.007255226373672485, 0.01000995934009552, 0.012764699757099152, 0.015519440174102783, 0.018274180591106415, 0.021028921008110046, 0.02378365397453308, 0.026538394391536713, 0.029293134808540344, 0.03204786777496338, 0.03480261564254761, 0.03755734860897064, 0.04031208157539368, 0.043066829442977905, 0.04582156240940094, 0.04857631027698517, 0.0513310432434082, 0.05408577620983124, 0.056840524077415466, 0.0595952570438385, 0.062349990010261536, 0.06510473787784576, 0.0678594708442688, 0.07061420381069183, 0.07336895167827606, 0.0761236846446991, 0.07887843251228333, 0.08163316547870636], "_type": "histogram", "values": [2, 0, 0, 0, 1, 2, 0, 1, 3, 3, 7, 8, 12, 13, 14, 22, 24, 25, 36, 53, 71, 103, 96, 140, 152, 177, 183, 193, 217, 252, 281, 265, 287, 317, 279, 288, 308, 294, 236, 255, 227, 228, 178, 169, 140, 123, 107, 83, 60, 37, 31, 34, 31, 20, 13, 12, 13, 7, 2, 3, 1, 1, 1, 3]}, "_runtime": 1542.1012663841248, "val_acc": 0.7733333333333333}
